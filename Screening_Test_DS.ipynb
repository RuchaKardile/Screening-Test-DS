{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Install the striprtf module\n",
        "!pip install striprtf\n",
        "\n",
        "#Read the RTF file and convert it to plain text\n",
        "from striprtf.striprtf import rtf_to_text\n",
        "\n",
        "# Read the RTF content from the file\n",
        "with open('/content/algoparams_from_ui.json.rtf', 'r') as file:\n",
        "    rtf_content = file.read()\n",
        "\n",
        "# Convert the RTF content to plain text\n",
        "plain_text = rtf_to_text(rtf_content)\n",
        "\n",
        "# Parse the JSON data\n",
        "import json\n",
        "\n",
        "# Since the plain text might have extra characters or invalid JSON, we need to clean it up\n",
        "\n",
        "try:\n",
        "    config = json.loads(plain_text)\n",
        "except json.JSONDecodeError as e:\n",
        "    print(\"Error decoding JSON:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9U2DsCjf05a",
        "outputId": "e70f43ca-2d38-4ecb-823b-691f19a95027"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: striprtf in /usr/local/lib/python3.10/dist-packages (0.0.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "sahOV3oo474N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) Read the target and type of regression to be run"
      ],
      "metadata": {
        "id": "dr7qlXekhPFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the target and type of regression\n",
        "target_info = config['design_state_data']['target']\n",
        "target = target_info['target']\n",
        "regression_type = target_info['type']\n",
        "\n",
        "print(f\"Target: {target}\")\n",
        "print(f\"Regression Type: {regression_type}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZZX8hDwhHTw",
        "outputId": "b6371751-d47d-4c73-ecba-3c853b87d315"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: petal_width\n",
            "Regression Type: regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) Read the features (which are column names in the csv) and figure out what missing imputation needs to be applied and apply that to the columns loaded in a dataframe\n"
      ],
      "metadata": {
        "id": "kFLcf7dEhSOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the CSV file into a DataFrame\n",
        "csv_file_path = '/content/iris.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Step 2: Read the imputation details from the JSON\n",
        "feature_handling = config['design_state_data']['feature_handling']\n",
        "\n",
        "# Step 3: Apply the imputation to the DataFrame\n",
        "for feature, details in feature_handling.items():\n",
        "    if details['is_selected']:\n",
        "        # Check if 'feature_details' exists and contains 'impute_with'\n",
        "        if 'feature_details' in details and 'impute_with' in details['feature_details']:\n",
        "            impute_method = details['feature_details']['impute_with']\n",
        "            impute_value = details['feature_details']['impute_value']\n",
        "\n",
        "            if impute_method == 'Average of values':\n",
        "                df[feature].fillna(df[feature].mean(), inplace=True)\n",
        "            elif impute_method == 'custom':\n",
        "                df[feature].fillna(impute_value, inplace=True)\n",
        "            else:\n",
        "                print(f\"Unknown imputation method for feature {feature}\")\n",
        "        else:\n",
        "            print(f\"Missing 'feature_details' or 'impute_with' for feature: {feature}\")\n",
        "\n",
        "print(\"DataFrame after imputation:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw2ujYSOjXnJ",
        "outputId": "8711105c-78ea-4fa6-805e-133dd79193f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing 'feature_details' or 'impute_with' for feature: species\n",
            "DataFrame after imputation:\n",
            "   sepal_length  sepal_width  petal_length  petal_width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) Compute feature reduction based on input. See the screenshot below where there can be No Reduction, Corr with Target, Tree-based, PCA. Please make sure you write code so that all options can work. If we rerun your code with a different Json it should work if we switch No Reduction to say PCA."
      ],
      "metadata": {
        "id": "a0NIPt9zbvLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Read the reduction method from JSON\n",
        "reduction_method = config['design_state_data']['feature_reduction']['feature_reduction_method']\n",
        "\n",
        "# Step 2: Handle categorical columns if present\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "if categorical_columns:\n",
        "    df = pd.get_dummies(df, columns=categorical_columns)\n",
        "\n",
        "# Step 3: Apply feature reduction based on the method chosen\n",
        "if reduction_method == 'No Reduction':\n",
        "    reduced_df = df\n",
        "\n",
        "elif reduction_method == 'Corr with Target':\n",
        "    target_variable = config['design_state_data']['target']['target']\n",
        "    corr = df.corrwith(df[target_variable])\n",
        "    selected_features = corr[abs(corr) > 0.2].index.tolist()\n",
        "    reduced_df = df[selected_features]\n",
        "\n",
        "elif reduction_method == 'Tree-based':\n",
        "    target_variable = config['design_state_data']['target']['target']\n",
        "    if config['design_state_data']['target']['type'] == 'classification':\n",
        "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    else:\n",
        "        clf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    clf.fit(df.drop(columns=[target_variable]), df[target_variable])\n",
        "    feature_importances = pd.Series(clf.feature_importances_, index=df.drop(columns=[target_variable]).columns)\n",
        "    selected_features = feature_importances[feature_importances > 0.01].index.tolist()\n",
        "    reduced_df = df[selected_features]\n",
        "\n",
        "elif reduction_method == 'PCA':\n",
        "    pca = PCA(n_components=3)\n",
        "    principal_components = pca.fit_transform(df)\n",
        "    reduced_df = pd.DataFrame(data=principal_components, columns=[f\"PC{i+1}\" for i in range(pca.n_components_)])\n",
        "\n",
        "else:\n",
        "    print(f\"Unknown feature reduction method: {reduction_method}\")\n",
        "\n",
        "print(\"DataFrame after feature reduction:\")\n",
        "print(reduced_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehu1cIZujzUO",
        "outputId": "b70666fe-4118-4091-8a6e-c1c2552574de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame after feature reduction:\n",
            "   sepal_length  sepal_width  petal_length  species_Iris-setosa  \\\n",
            "0           5.1          3.5           1.4                 True   \n",
            "1           4.9          3.0           1.4                 True   \n",
            "2           4.7          3.2           1.3                 True   \n",
            "3           4.6          3.1           1.5                 True   \n",
            "4           5.0          3.6           1.4                 True   \n",
            "\n",
            "   species_Iris-versicolor  species_Iris-virginica  \n",
            "0                    False                   False  \n",
            "1                    False                   False  \n",
            "2                    False                   False  \n",
            "3                    False                   False  \n",
            "4                    False                   False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4) Parse the Json and make the model objects (using sklean) that can handle what is required in the “prediction_type” specified in the JSON (See 1 where “prediction_type” is specified). Keep in mind not to pick models that don’t apply for the prediction_type specified"
      ],
      "metadata": {
        "id": "CTdkxhqwcTyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Parse the prediction type\n",
        "prediction_type = config['design_state_data']['target']['prediction_type']\n",
        "\n",
        "# Step 2: Create model objects based on prediction type\n",
        "def create_model_objects(config, prediction_type):\n",
        "    models = []\n",
        "\n",
        "    for model_key, model_info in config['design_state_data']['algorithms'].items():\n",
        "        if model_info['is_selected']:\n",
        "            if prediction_type == \"Regression\":\n",
        "                if model_key == \"RandomForestRegressor\":\n",
        "                    model = RandomForestRegressor(\n",
        "                        n_estimators=model_info.get('max_trees', 100),\n",
        "                        max_depth=model_info.get('max_depth', None),\n",
        "                        min_samples_leaf=model_info.get('min_samples_per_leaf_min_value', 1)\n",
        "                    )\n",
        "                    models.append(model)\n",
        "                elif model_key == \"LinearRegression\":\n",
        "                    model = LinearRegression()\n",
        "                    models.append(model)\n",
        "                elif model_key == \"DecisionTreeRegressor\":\n",
        "                    model = DecisionTreeRegressor(\n",
        "                        max_depth=model_info.get('max_depth', None),\n",
        "                        min_samples_leaf=model_info.get('min_samples_per_leaf_min_value', 1)\n",
        "                    )\n",
        "                    models.append(model)\n",
        "                elif model_key == \"SVR\":\n",
        "                    model = SVR()\n",
        "                    models.append(model)\n",
        "\n",
        "            elif prediction_type == \"Classification\":\n",
        "                if model_key == \"RandomForestClassifier\":\n",
        "                    model = RandomForestClassifier(\n",
        "                        n_estimators=model_info.get('max_trees', 100),\n",
        "                        max_depth=model_info.get('max_depth', None),\n",
        "                        min_samples_leaf=model_info.get('min_samples_per_leaf_min_value', 1)\n",
        "                    )\n",
        "                    models.append(model)\n",
        "                elif model_key == \"LogisticRegression\":\n",
        "                    model = LogisticRegression()\n",
        "                    models.append(model)\n",
        "                elif model_key == \"DecisionTreeClassifier\":\n",
        "                    model = DecisionTreeClassifier(\n",
        "                        max_depth=model_info.get('max_depth', None),\n",
        "                        min_samples_leaf=model_info.get('min_samples_per_leaf_min_value', 1)\n",
        "                    )\n",
        "                    models.append(model)\n",
        "                elif model_key == \"SVC\":\n",
        "                    model = SVC()\n",
        "                    models.append(model)\n",
        "    return models\n",
        "\n",
        "# Step 3: Create the models\n",
        "model_objects = create_model_objects(config, prediction_type)\n",
        "\n",
        "# Output the models created\n",
        "for model in model_objects:\n",
        "    print(model)\n"
      ],
      "metadata": {
        "id": "qsm1q55Dj_cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8aa035c-9123-417b-a137-fa956bc97384"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestRegressor(max_depth=25, min_samples_leaf=5, n_estimators=20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5) Run the fit and predict on each model – keep in mind that you need to do hyper parameter tuning i.e., use GridSearchCV"
      ],
      "metadata": {
        "id": "iUmBFlcQgNz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Parse the prediction type\n",
        "prediction_type = config['design_state_data']['target']['prediction_type']\n",
        "target_variable = config['design_state_data']['target']['target']\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/iris.csv')\n",
        "\n",
        "# Step 2: Preprocessing - Encode categorical variables\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# Ensure target variable is not included in feature columns\n",
        "categorical_cols = [col for col in categorical_cols if col != target_variable]\n",
        "numerical_cols = [col for col in numerical_cols if col != target_variable]\n",
        "\n",
        "# Define the preprocessing for numerical and categorical data\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Step 3: Create model objects based on prediction type\n",
        "def create_model_objects(config, prediction_type):\n",
        "    models = []\n",
        "    param_grids = {}\n",
        "\n",
        "    for model_key, model_info in config['design_state_data']['algorithms'].items():\n",
        "        if model_info['is_selected']:\n",
        "            if prediction_type == \"Regression\":\n",
        "                if model_key == \"RandomForestRegressor\":\n",
        "                    model = RandomForestRegressor(random_state=42)\n",
        "                    param_grid = {\n",
        "                        'model__n_estimators': range(model_info['min_trees'], model_info['max_trees']+1, 10),\n",
        "                        'model__max_depth': range(model_info['min_depth'], model_info['max_depth']+1, 5),\n",
        "                        'model__min_samples_leaf': range(model_info['min_samples_per_leaf_min_value'], model_info['min_samples_per_leaf_max_value']+1, 5)\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"LinearRegression\":\n",
        "                    model = LinearRegression()\n",
        "                    param_grid = {}  # No hyperparameters to tune for LinearRegression\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"DecisionTreeRegressor\":\n",
        "                    model = DecisionTreeRegressor(random_state=42)\n",
        "                    param_grid = {\n",
        "                        'model__max_depth': range(model_info['min_depth'], model_info['max_depth']+1, 5),\n",
        "                        'model__min_samples_leaf': range(model_info['min_samples_per_leaf_min_value'], model_info['min_samples_per_leaf_max_value']+1, 5)\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"SVR\":\n",
        "                    model = SVR()\n",
        "                    param_grid = {\n",
        "                        'model__C': [0.1, 1, 10],\n",
        "                        'model__gamma': ['scale', 'auto']\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "            elif prediction_type == \"Classification\":\n",
        "                if model_key == \"RandomForestClassifier\":\n",
        "                    model = RandomForestClassifier(random_state=42)\n",
        "                    param_grid = {\n",
        "                        'model__n_estimators': range(model_info['min_trees'], model_info['max_trees']+1, 10),\n",
        "                        'model__max_depth': range(model_info['min_depth'], model_info['max_depth']+1, 5),\n",
        "                        'model__min_samples_leaf': range(model_info['min_samples_per_leaf_min_value'], model_info['min_samples_per_leaf_max_value']+1, 5)\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"LogisticRegression\":\n",
        "                    model = LogisticRegression(max_iter=10000)\n",
        "                    param_grid = {\n",
        "                        'model__C': [0.1, 1, 10],\n",
        "                        'model__solver': ['liblinear', 'lbfgs']\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"DecisionTreeClassifier\":\n",
        "                    model = DecisionTreeClassifier(random_state=42)\n",
        "                    param_grid = {\n",
        "                        'model__max_depth': range(model_info['min_depth'], model_info['max_depth']+1, 5),\n",
        "                        'model__min_samples_leaf': range(model_info['min_samples_per_leaf_min_value'], model_info['min_samples_per_leaf_max_value']+1, 5)\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"SVC\":\n",
        "                    model = SVC()\n",
        "                    param_grid = {\n",
        "                        'model__C': [0.1, 1, 10],\n",
        "                        'model__gamma': ['scale', 'auto']\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "    return models, param_grids\n",
        "\n",
        "# Step 4: Create the models and parameter grids\n",
        "model_objects, param_grids = create_model_objects(config, prediction_type)\n",
        "\n",
        "# Step 5: Fit models using GridSearchCV and make predictions\n",
        "X = df.drop(columns=[target_variable])\n",
        "y = df[target_variable]\n",
        "\n",
        "best_models = []\n",
        "for model, param_grid in zip(model_objects, param_grids.values()):\n",
        "    # Create a pipeline that includes preprocessing and the model\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('model', model)])\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error' if prediction_type == 'Regression' else 'accuracy')\n",
        "    grid_search.fit(X, y)\n",
        "    best_models.append(grid_search.best_estimator_)\n",
        "    print(f\"Best parameters for {type(model).__name__}: {grid_search.best_params_}\")\n",
        "\n",
        "# Step 6: Make predictions with the best models\n",
        "predictions = {}\n",
        "for best_model in best_models:\n",
        "    pred = best_model.predict(X)\n",
        "    predictions[type(best_model.named_steps['model']).__name__] = pred\n",
        "\n",
        "# Output the predictions\n",
        "for model_name, pred in predictions.items():\n",
        "    print(f\"Predictions for {model_name}: {pred}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X24moQxLgOOt",
        "outputId": "4cd142bd-9b4b-4272-fce2-fb76ded8c765"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForestRegressor: {'model__max_depth': 20, 'model__min_samples_leaf': 5, 'model__n_estimators': 20}\n",
            "Predictions for RandomForestRegressor: [0.24897008 0.17452089 0.20873373 0.18459271 0.22793789 0.33564868\n",
            " 0.23166045 0.23253419 0.19647637 0.16139195 0.26921806 0.26966758\n",
            " 0.18457155 0.19897637 0.2573159  0.27219425 0.2573159  0.24897008\n",
            " 0.33564868 0.26283808 0.32287325 0.25986189 0.23082712 0.30212578\n",
            " 0.28572313 0.25255717 0.27855646 0.25041895 0.23848931 0.26661676\n",
            " 0.25264051 0.26027298 0.25335731 0.2573159  0.16139195 0.193282\n",
            " 0.2545613  0.16139195 0.19897637 0.25223305 0.23427122 0.19897637\n",
            " 0.21092123 0.29359813 0.32800222 0.18457155 0.31578    0.20842123\n",
            " 0.25997203 0.20485397 1.51128149 1.49669816 1.59200663 1.15960363\n",
            " 1.4207612  1.42560796 1.52361483 1.02702048 1.42667029 1.25893994\n",
            " 1.06271492 1.31951723 1.14952946 1.4504322  1.188829   1.34992109\n",
            " 1.48712337 1.24615743 1.42993977 1.1655322  1.58718917 1.25135584\n",
            " 1.48010562 1.4445231  1.31776647 1.34992109 1.5003834  1.56840827\n",
            " 1.45390991 1.08461373 1.10241135 1.06271492 1.23532409 1.52239957\n",
            " 1.48712337 1.51742832 1.51128149 1.31074868 1.27013041 1.17922268\n",
            " 1.30097121 1.49921464 1.17428541 1.02702048 1.30870725 1.30904974\n",
            " 1.3030882  1.32151647 1.04663953 1.26129708 2.27307296 1.93193619\n",
            " 2.01713752 1.84214867 2.04267136 1.98326847 1.77905262 1.9550899\n",
            " 1.99102868 2.24189507 2.18542326 1.99135317 2.05054167 1.80474135\n",
            " 1.93193619 2.17542326 2.03992929 2.24189507 1.94010974 1.75756422\n",
            " 2.18897553 1.82893778 1.96022879 1.75030105 2.32456034 2.10637297\n",
            " 1.75030105 1.7823989  1.99202778 1.98492323 1.96022879 2.24189507\n",
            " 1.99202778 1.85329946 1.84998922 1.98326847 2.2826563  2.08990081\n",
            " 1.79582315 2.12646263 2.17145925 2.13924041 1.93193619 2.18145767\n",
            " 2.32456034 2.08197024 1.73519553 2.07135786 2.24862852 1.93644918]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####6) Log to the console the standard model metrics that apply"
      ],
      "metadata": {
        "id": "1CzplGGi3-7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Parse the prediction type\n",
        "prediction_type = config['design_state_data']['target']['prediction_type']\n",
        "target_variable = config['design_state_data']['target']['target']\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/iris.csv')\n",
        "\n",
        "# Step 2: Preprocessing - Encode categorical variables\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# Ensure target variable is not included in feature columns\n",
        "categorical_cols = [col for col in categorical_cols if col != target_variable]\n",
        "numerical_cols = [col for col in numerical_cols if col != target_variable]\n",
        "\n",
        "# Define the preprocessing for numerical and categorical data\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Step 3: Create model objects based on prediction type\n",
        "def create_model_objects(config, prediction_type):\n",
        "    models = []\n",
        "    param_grids = {}\n",
        "\n",
        "    for model_key, model_info in config['design_state_data']['algorithms'].items():\n",
        "        if model_info['is_selected']:\n",
        "            if prediction_type == \"Regression\":\n",
        "                if model_key == \"RandomForestRegressor\":\n",
        "                    model = RandomForestRegressor(random_state=42)\n",
        "                    param_grid = {\n",
        "                        'model__n_estimators': range(model_info['min_trees'], model_info['max_trees']+1, 10),\n",
        "                        'model__max_depth': range(model_info['min_depth'], model_info['max_depth']+1, 5),\n",
        "                        'model__min_samples_leaf': range(model_info['min_samples_per_leaf_min_value'], model_info['min_samples_per_leaf_max_value']+1, 5)\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"LinearRegression\":\n",
        "                    model = LinearRegression()\n",
        "                    param_grid = {}  # No hyperparameters to tune for LinearRegression\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"DecisionTreeRegressor\":\n",
        "                    model = DecisionTreeRegressor(random_state=42)\n",
        "                    param_grid = {\n",
        "                        'model__max_depth': range(model_info['min_depth'], model_info['max_depth']+1, 5),\n",
        "                        'model__min_samples_leaf': range(model_info['min_samples_per_leaf_min_value'], model_info['min_samples_per_leaf_max_value']+1, 5)\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"SVR\":\n",
        "                    model = SVR()\n",
        "                    param_grid = {\n",
        "                        'model__C': [0.1, 1, 10],\n",
        "                        'model__gamma': ['scale', 'auto']\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "            elif prediction_type == \"Classification\":\n",
        "                if model_key == \"RandomForestClassifier\":\n",
        "                    model = RandomForestClassifier(random_state=42)\n",
        "                    param_grid = {\n",
        "                        'model__n_estimators': range(model_info['min_trees'], model_info['max_trees']+1, 10),\n",
        "                        'model__max_depth': range(model_info['min_depth'], model_info['max_depth']+1, 5),\n",
        "                        'model__min_samples_leaf': range(model_info['min_samples_per_leaf_min_value'], model_info['min_samples_per_leaf_max_value']+1, 5)\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"LogisticRegression\":\n",
        "                    model = LogisticRegression(max_iter=10000)\n",
        "                    param_grid = {\n",
        "                        'model__C': [0.1, 1, 10],\n",
        "                        'model__solver': ['liblinear', 'lbfgs']\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"DecisionTreeClassifier\":\n",
        "                    model = DecisionTreeClassifier(random_state=42)\n",
        "                    param_grid = {\n",
        "                        'model__max_depth': range(model_info['min_depth'], model_info['max_depth']+1, 5),\n",
        "                        'model__min_samples_leaf': range(model_info['min_samples_per_leaf_min_value'], model_info['min_samples_per_leaf_max_value']+1, 5)\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "                elif model_key == \"SVC\":\n",
        "                    model = SVC()\n",
        "                    param_grid = {\n",
        "                        'model__C': [0.1, 1, 10],\n",
        "                        'model__gamma': ['scale', 'auto']\n",
        "                    }\n",
        "                    models.append(model)\n",
        "                    param_grids[model_key] = param_grid\n",
        "\n",
        "    return models, param_grids\n",
        "\n",
        "# Step 4: Create the models and parameter grids\n",
        "model_objects, param_grids = create_model_objects(config, prediction_type)\n",
        "\n",
        "# Step 5: Fit models using GridSearchCV and make predictions\n",
        "X = df.drop(columns=[target_variable])\n",
        "y = df[target_variable]\n",
        "\n",
        "best_models = []\n",
        "for model, param_grid in zip(model_objects, param_grids.values()):\n",
        "    # Create a pipeline that includes preprocessing and the model\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('model', model)])\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error' if prediction_type == 'Regression' else 'accuracy')\n",
        "    grid_search.fit(X, y)\n",
        "    best_models.append(grid_search.best_estimator_)\n",
        "    print(f\"Best parameters for {type(model).__name__}: {grid_search.best_params_}\")\n",
        "\n",
        "# Step 6: Make predictions with the best models and log metrics\n",
        "predictions = {}\n",
        "for best_model in best_models:\n",
        "    pred = best_model.predict(X)\n",
        "    predictions[type(best_model.named_steps['model']).__name__] = pred\n",
        "\n",
        "# Log metrics\n",
        "for model_name, pred in predictions.items():\n",
        "    if prediction_type == \"Regression\":\n",
        "        mse = mean_squared_error(y, pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(y, pred)\n",
        "        r2 = r2_score(y, pred)\n",
        "        print(f\"{model_name} - MSE: {mse}, RMSE: {rmse}, MAE: {mae}, R²: {r2}\")\n",
        "    elif prediction_type == \"Classification\":\n",
        "        accuracy = accuracy_score(y, pred)\n",
        "        precision = precision_score(y, pred, average='macro')\n",
        "        recall = recall_score(y, pred, average='macro')\n",
        "        f1 = f1_score(y, pred, average='macro')\n",
        "        print(f\"{model_name} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
        "\n",
        "# Output the predictions\n",
        "for model_name, pred in predictions.items():\n",
        "    print(f\"Predictions for {model_name}: {pred}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgrvg0s93-l7",
        "outputId": "20dd144a-4a82-4426-9877-3a5cb794a506"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForestRegressor: {'model__max_depth': 20, 'model__min_samples_leaf': 5, 'model__n_estimators': 20}\n",
            "RandomForestRegressor - MSE: 0.019268274620558613, RMSE: 0.1388102107935818, MAE: 0.10395376163868812, R²: 0.9666945140061451\n",
            "Predictions for RandomForestRegressor: [0.24897008 0.17452089 0.20873373 0.18459271 0.22793789 0.33564868\n",
            " 0.23166045 0.23253419 0.19647637 0.16139195 0.26921806 0.26966758\n",
            " 0.18457155 0.19897637 0.2573159  0.27219425 0.2573159  0.24897008\n",
            " 0.33564868 0.26283808 0.32287325 0.25986189 0.23082712 0.30212578\n",
            " 0.28572313 0.25255717 0.27855646 0.25041895 0.23848931 0.26661676\n",
            " 0.25264051 0.26027298 0.25335731 0.2573159  0.16139195 0.193282\n",
            " 0.2545613  0.16139195 0.19897637 0.25223305 0.23427122 0.19897637\n",
            " 0.21092123 0.29359813 0.32800222 0.18457155 0.31578    0.20842123\n",
            " 0.25997203 0.20485397 1.51128149 1.49669816 1.59200663 1.15960363\n",
            " 1.4207612  1.42560796 1.52361483 1.02702048 1.42667029 1.25893994\n",
            " 1.06271492 1.31951723 1.14952946 1.4504322  1.188829   1.34992109\n",
            " 1.48712337 1.24615743 1.42993977 1.1655322  1.58718917 1.25135584\n",
            " 1.48010562 1.4445231  1.31776647 1.34992109 1.5003834  1.56840827\n",
            " 1.45390991 1.08461373 1.10241135 1.06271492 1.23532409 1.52239957\n",
            " 1.48712337 1.51742832 1.51128149 1.31074868 1.27013041 1.17922268\n",
            " 1.30097121 1.49921464 1.17428541 1.02702048 1.30870725 1.30904974\n",
            " 1.3030882  1.32151647 1.04663953 1.26129708 2.27307296 1.93193619\n",
            " 2.01713752 1.84214867 2.04267136 1.98326847 1.77905262 1.9550899\n",
            " 1.99102868 2.24189507 2.18542326 1.99135317 2.05054167 1.80474135\n",
            " 1.93193619 2.17542326 2.03992929 2.24189507 1.94010974 1.75756422\n",
            " 2.18897553 1.82893778 1.96022879 1.75030105 2.32456034 2.10637297\n",
            " 1.75030105 1.7823989  1.99202778 1.98492323 1.96022879 2.24189507\n",
            " 1.99202778 1.85329946 1.84998922 1.98326847 2.2826563  2.08990081\n",
            " 1.79582315 2.12646263 2.17145925 2.13924041 1.93193619 2.18145767\n",
            " 2.32456034 2.08197024 1.73519553 2.07135786 2.24862852 1.93644918]\n"
          ]
        }
      ]
    }
  ]
}